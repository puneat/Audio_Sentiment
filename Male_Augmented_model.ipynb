{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Male_Augmented_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4l8q5ezLF123o5/2iZzww",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puneat/Audio_Sentiment/blob/puneet/Male_Augmented_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8gT1gielKJ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "bf25a72b-850b-4407-a5df-5ef598f5b7f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "UDSKwLYHkYMd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "3dcecf44-e75f-4cd0-9331-fc79edc6c574"
      },
      "source": [
        "# Importing required libraries \n",
        "# Keras\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, Model, model_from_json\n",
        "from keras.layers import Dense, Embedding, LSTM\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# sklearn\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Other  \n",
        "import librosa\n",
        "import librosa.display\n",
        "import json\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import glob \n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import IPython.display as ipd  # To play sound in the notebook"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "861Vn4Vyl59z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('/gdrive/My Drive/Audio_files/Combined_Dataframes/augmented_male.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTl-1RdpkYOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "4b0133ce-cea2-41bb-b7e8-45bb773022d5"
      },
      "source": [
        "# Split between train and test \n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop(['path','labels','source'],axis=1)\n",
        "                                                    , df.labels\n",
        "                                                    , test_size=0.20\n",
        "                                                    , shuffle=True\n",
        "                                                    , random_state=42\n",
        "                                                   )\n",
        "\n",
        "#data before normalisation \n",
        "X_train[150:160]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22678</th>\n",
              "      <td>2158</td>\n",
              "      <td>-19.770191</td>\n",
              "      <td>-17.820446</td>\n",
              "      <td>-17.172469</td>\n",
              "      <td>-14.361007</td>\n",
              "      <td>-14.878365</td>\n",
              "      <td>-16.168246</td>\n",
              "      <td>-15.969766</td>\n",
              "      <td>-16.005413</td>\n",
              "      <td>-17.098746</td>\n",
              "      <td>-15.539544</td>\n",
              "      <td>-13.998212</td>\n",
              "      <td>-13.713506</td>\n",
              "      <td>-11.750972</td>\n",
              "      <td>-11.701815</td>\n",
              "      <td>-12.895173</td>\n",
              "      <td>-13.193752</td>\n",
              "      <td>-15.526430</td>\n",
              "      <td>-15.676518</td>\n",
              "      <td>-14.067893</td>\n",
              "      <td>-15.472958</td>\n",
              "      <td>-16.528864</td>\n",
              "      <td>-15.441254</td>\n",
              "      <td>-12.279467</td>\n",
              "      <td>-10.657224</td>\n",
              "      <td>-11.357713</td>\n",
              "      <td>-10.613318</td>\n",
              "      <td>-10.325374</td>\n",
              "      <td>-10.473237</td>\n",
              "      <td>-11.301556</td>\n",
              "      <td>-12.757654</td>\n",
              "      <td>-12.554570</td>\n",
              "      <td>-12.212356</td>\n",
              "      <td>-15.036889</td>\n",
              "      <td>-17.622550</td>\n",
              "      <td>-15.972091</td>\n",
              "      <td>-14.625575</td>\n",
              "      <td>-14.088717</td>\n",
              "      <td>-13.612458</td>\n",
              "      <td>-14.789350</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27102</th>\n",
              "      <td>1452</td>\n",
              "      <td>-18.470215</td>\n",
              "      <td>-18.634213</td>\n",
              "      <td>-17.348700</td>\n",
              "      <td>-15.328758</td>\n",
              "      <td>-15.381434</td>\n",
              "      <td>-14.881728</td>\n",
              "      <td>-14.212455</td>\n",
              "      <td>-12.226182</td>\n",
              "      <td>-11.949044</td>\n",
              "      <td>-12.550916</td>\n",
              "      <td>-14.027365</td>\n",
              "      <td>-15.693438</td>\n",
              "      <td>-15.010396</td>\n",
              "      <td>-15.579869</td>\n",
              "      <td>-15.537688</td>\n",
              "      <td>-15.171172</td>\n",
              "      <td>-13.359892</td>\n",
              "      <td>-12.793194</td>\n",
              "      <td>-13.889895</td>\n",
              "      <td>-13.812256</td>\n",
              "      <td>-12.941505</td>\n",
              "      <td>-14.517511</td>\n",
              "      <td>-16.258690</td>\n",
              "      <td>-15.755478</td>\n",
              "      <td>-14.633683</td>\n",
              "      <td>-15.841612</td>\n",
              "      <td>-14.836003</td>\n",
              "      <td>-14.990748</td>\n",
              "      <td>-14.909520</td>\n",
              "      <td>-12.901282</td>\n",
              "      <td>-12.355986</td>\n",
              "      <td>-12.152347</td>\n",
              "      <td>-11.830311</td>\n",
              "      <td>-10.616625</td>\n",
              "      <td>-11.080653</td>\n",
              "      <td>-12.363033</td>\n",
              "      <td>-12.449130</td>\n",
              "      <td>-11.009433</td>\n",
              "      <td>-12.825597</td>\n",
              "      <td>...</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-39.570224</td>\n",
              "      <td>-28.874165</td>\n",
              "      <td>-19.419418</td>\n",
              "      <td>-16.332369</td>\n",
              "      <td>-17.411228</td>\n",
              "      <td>-16.866331</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3584</th>\n",
              "      <td>3584</td>\n",
              "      <td>-3.463185</td>\n",
              "      <td>-7.545588</td>\n",
              "      <td>-14.848887</td>\n",
              "      <td>-15.441847</td>\n",
              "      <td>-15.028918</td>\n",
              "      <td>-14.971291</td>\n",
              "      <td>-14.269434</td>\n",
              "      <td>-14.801823</td>\n",
              "      <td>-16.023823</td>\n",
              "      <td>-15.481306</td>\n",
              "      <td>-8.427888</td>\n",
              "      <td>-7.484760</td>\n",
              "      <td>-13.050666</td>\n",
              "      <td>-10.841432</td>\n",
              "      <td>-10.418455</td>\n",
              "      <td>-10.521139</td>\n",
              "      <td>-7.367857</td>\n",
              "      <td>-4.449355</td>\n",
              "      <td>-5.866468</td>\n",
              "      <td>-12.711026</td>\n",
              "      <td>-13.946189</td>\n",
              "      <td>-14.309726</td>\n",
              "      <td>-12.547684</td>\n",
              "      <td>-12.579071</td>\n",
              "      <td>-15.594072</td>\n",
              "      <td>-18.169230</td>\n",
              "      <td>-15.468671</td>\n",
              "      <td>-17.139344</td>\n",
              "      <td>-17.015953</td>\n",
              "      <td>-16.487126</td>\n",
              "      <td>-19.304447</td>\n",
              "      <td>-17.789947</td>\n",
              "      <td>-14.430106</td>\n",
              "      <td>-15.071532</td>\n",
              "      <td>-14.002765</td>\n",
              "      <td>-13.830706</td>\n",
              "      <td>-13.733434</td>\n",
              "      <td>-10.537228</td>\n",
              "      <td>-9.873762</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888</th>\n",
              "      <td>1888</td>\n",
              "      <td>-23.718474</td>\n",
              "      <td>-20.618072</td>\n",
              "      <td>-17.807260</td>\n",
              "      <td>-19.064650</td>\n",
              "      <td>-17.800028</td>\n",
              "      <td>-16.130265</td>\n",
              "      <td>-15.282562</td>\n",
              "      <td>-11.925191</td>\n",
              "      <td>-12.580800</td>\n",
              "      <td>-12.265557</td>\n",
              "      <td>-11.412405</td>\n",
              "      <td>-10.974491</td>\n",
              "      <td>-10.423262</td>\n",
              "      <td>-11.200537</td>\n",
              "      <td>-11.334430</td>\n",
              "      <td>-11.781767</td>\n",
              "      <td>-11.962812</td>\n",
              "      <td>-12.664647</td>\n",
              "      <td>-14.975012</td>\n",
              "      <td>-17.376903</td>\n",
              "      <td>-17.249843</td>\n",
              "      <td>-17.091736</td>\n",
              "      <td>-17.923140</td>\n",
              "      <td>-13.648929</td>\n",
              "      <td>-12.432248</td>\n",
              "      <td>-11.585258</td>\n",
              "      <td>-12.116064</td>\n",
              "      <td>-14.541969</td>\n",
              "      <td>-18.015712</td>\n",
              "      <td>-17.273672</td>\n",
              "      <td>-17.688054</td>\n",
              "      <td>-17.970072</td>\n",
              "      <td>-18.072219</td>\n",
              "      <td>-17.098370</td>\n",
              "      <td>-13.962287</td>\n",
              "      <td>-15.191273</td>\n",
              "      <td>-18.920876</td>\n",
              "      <td>-18.606639</td>\n",
              "      <td>-17.700299</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.403998</td>\n",
              "      <td>-17.395160</td>\n",
              "      <td>-17.217328</td>\n",
              "      <td>-18.674013</td>\n",
              "      <td>-20.092665</td>\n",
              "      <td>-19.631804</td>\n",
              "      <td>-20.346772</td>\n",
              "      <td>-22.052234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7138</th>\n",
              "      <td>2008</td>\n",
              "      <td>1.776653</td>\n",
              "      <td>-1.903978</td>\n",
              "      <td>-12.248746</td>\n",
              "      <td>-10.059386</td>\n",
              "      <td>-9.470712</td>\n",
              "      <td>-8.762602</td>\n",
              "      <td>-11.207290</td>\n",
              "      <td>-12.512509</td>\n",
              "      <td>-13.232669</td>\n",
              "      <td>-13.550707</td>\n",
              "      <td>-11.436189</td>\n",
              "      <td>-12.119967</td>\n",
              "      <td>-12.320873</td>\n",
              "      <td>-14.536313</td>\n",
              "      <td>-15.901869</td>\n",
              "      <td>-14.237517</td>\n",
              "      <td>-13.315524</td>\n",
              "      <td>-15.105322</td>\n",
              "      <td>-16.199096</td>\n",
              "      <td>-14.231690</td>\n",
              "      <td>-10.130239</td>\n",
              "      <td>-9.654405</td>\n",
              "      <td>-7.975957</td>\n",
              "      <td>-6.780436</td>\n",
              "      <td>-6.441665</td>\n",
              "      <td>-5.973769</td>\n",
              "      <td>-7.497015</td>\n",
              "      <td>-6.825514</td>\n",
              "      <td>-8.094548</td>\n",
              "      <td>-10.180581</td>\n",
              "      <td>-9.898857</td>\n",
              "      <td>-10.754988</td>\n",
              "      <td>-10.999878</td>\n",
              "      <td>-11.198864</td>\n",
              "      <td>-9.463021</td>\n",
              "      <td>-9.427083</td>\n",
              "      <td>-10.461188</td>\n",
              "      <td>-7.400341</td>\n",
              "      <td>-7.110035</td>\n",
              "      <td>...</td>\n",
              "      <td>-17.300394</td>\n",
              "      <td>-15.908964</td>\n",
              "      <td>-14.024036</td>\n",
              "      <td>-13.582347</td>\n",
              "      <td>-15.887627</td>\n",
              "      <td>-15.168051</td>\n",
              "      <td>-16.934802</td>\n",
              "      <td>-15.863000</td>\n",
              "      <td>-14.971655</td>\n",
              "      <td>-15.382840</td>\n",
              "      <td>-15.599078</td>\n",
              "      <td>-16.002082</td>\n",
              "      <td>-17.047869</td>\n",
              "      <td>-20.413191</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13134</th>\n",
              "      <td>2874</td>\n",
              "      <td>-18.160437</td>\n",
              "      <td>-16.969181</td>\n",
              "      <td>-16.617464</td>\n",
              "      <td>-16.063655</td>\n",
              "      <td>-15.916027</td>\n",
              "      <td>-15.470968</td>\n",
              "      <td>-15.177052</td>\n",
              "      <td>-13.255790</td>\n",
              "      <td>-12.441230</td>\n",
              "      <td>-14.412684</td>\n",
              "      <td>-15.173223</td>\n",
              "      <td>-14.831577</td>\n",
              "      <td>-17.013414</td>\n",
              "      <td>-18.788753</td>\n",
              "      <td>-17.654805</td>\n",
              "      <td>-15.470554</td>\n",
              "      <td>-12.611120</td>\n",
              "      <td>-14.610356</td>\n",
              "      <td>-16.894299</td>\n",
              "      <td>-16.831617</td>\n",
              "      <td>-18.376105</td>\n",
              "      <td>-18.094111</td>\n",
              "      <td>-17.938608</td>\n",
              "      <td>-17.399751</td>\n",
              "      <td>-15.732987</td>\n",
              "      <td>-14.479782</td>\n",
              "      <td>-16.342892</td>\n",
              "      <td>-15.732322</td>\n",
              "      <td>-14.978911</td>\n",
              "      <td>-17.166049</td>\n",
              "      <td>-18.290739</td>\n",
              "      <td>-14.050858</td>\n",
              "      <td>-14.036618</td>\n",
              "      <td>-16.437138</td>\n",
              "      <td>-16.097778</td>\n",
              "      <td>-15.365690</td>\n",
              "      <td>-16.961172</td>\n",
              "      <td>-18.265209</td>\n",
              "      <td>-16.435136</td>\n",
              "      <td>...</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>-49.254998</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22992</th>\n",
              "      <td>2472</td>\n",
              "      <td>1.497068</td>\n",
              "      <td>-1.872089</td>\n",
              "      <td>-4.313685</td>\n",
              "      <td>-5.744134</td>\n",
              "      <td>-5.842545</td>\n",
              "      <td>-3.591132</td>\n",
              "      <td>-2.104090</td>\n",
              "      <td>-2.991771</td>\n",
              "      <td>-3.584157</td>\n",
              "      <td>-1.277507</td>\n",
              "      <td>-0.617140</td>\n",
              "      <td>-2.288241</td>\n",
              "      <td>-3.253185</td>\n",
              "      <td>-1.216784</td>\n",
              "      <td>-3.143710</td>\n",
              "      <td>-7.054642</td>\n",
              "      <td>-8.288776</td>\n",
              "      <td>-8.657157</td>\n",
              "      <td>-6.536400</td>\n",
              "      <td>-7.703720</td>\n",
              "      <td>-5.391786</td>\n",
              "      <td>-6.516009</td>\n",
              "      <td>-9.349710</td>\n",
              "      <td>-6.849851</td>\n",
              "      <td>-7.559328</td>\n",
              "      <td>-6.937628</td>\n",
              "      <td>-8.560872</td>\n",
              "      <td>-7.477595</td>\n",
              "      <td>-6.634110</td>\n",
              "      <td>-6.851878</td>\n",
              "      <td>-7.296031</td>\n",
              "      <td>-5.641842</td>\n",
              "      <td>-6.288074</td>\n",
              "      <td>-5.313912</td>\n",
              "      <td>-5.652078</td>\n",
              "      <td>-5.463321</td>\n",
              "      <td>-4.513536</td>\n",
              "      <td>-4.189831</td>\n",
              "      <td>-5.849576</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10397</th>\n",
              "      <td>137</td>\n",
              "      <td>-25.805083</td>\n",
              "      <td>-24.362060</td>\n",
              "      <td>-19.737274</td>\n",
              "      <td>-14.705759</td>\n",
              "      <td>-15.183760</td>\n",
              "      <td>-16.352636</td>\n",
              "      <td>-15.571728</td>\n",
              "      <td>-13.180413</td>\n",
              "      <td>-12.040184</td>\n",
              "      <td>-12.469129</td>\n",
              "      <td>-13.487675</td>\n",
              "      <td>-15.215775</td>\n",
              "      <td>-14.813664</td>\n",
              "      <td>-15.596394</td>\n",
              "      <td>-15.930052</td>\n",
              "      <td>-12.025293</td>\n",
              "      <td>-9.539891</td>\n",
              "      <td>-10.589793</td>\n",
              "      <td>-13.930762</td>\n",
              "      <td>-14.310446</td>\n",
              "      <td>-16.364786</td>\n",
              "      <td>-16.413688</td>\n",
              "      <td>-19.848208</td>\n",
              "      <td>-22.854353</td>\n",
              "      <td>-23.970776</td>\n",
              "      <td>-20.273527</td>\n",
              "      <td>-16.630798</td>\n",
              "      <td>-13.612848</td>\n",
              "      <td>-14.000094</td>\n",
              "      <td>-14.941265</td>\n",
              "      <td>-16.471586</td>\n",
              "      <td>-17.034151</td>\n",
              "      <td>-18.652453</td>\n",
              "      <td>-18.703828</td>\n",
              "      <td>-17.775884</td>\n",
              "      <td>-17.061384</td>\n",
              "      <td>-15.283596</td>\n",
              "      <td>-12.826526</td>\n",
              "      <td>-12.757338</td>\n",
              "      <td>...</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "      <td>-42.601091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5550</th>\n",
              "      <td>420</td>\n",
              "      <td>-18.971343</td>\n",
              "      <td>-18.861279</td>\n",
              "      <td>-19.517397</td>\n",
              "      <td>-19.033060</td>\n",
              "      <td>-16.835389</td>\n",
              "      <td>-18.307525</td>\n",
              "      <td>-18.322991</td>\n",
              "      <td>-17.328688</td>\n",
              "      <td>-18.547109</td>\n",
              "      <td>-17.262663</td>\n",
              "      <td>-7.765700</td>\n",
              "      <td>-3.946076</td>\n",
              "      <td>-5.026870</td>\n",
              "      <td>-6.190178</td>\n",
              "      <td>-5.597152</td>\n",
              "      <td>-6.329260</td>\n",
              "      <td>-8.234272</td>\n",
              "      <td>-8.005110</td>\n",
              "      <td>-7.501497</td>\n",
              "      <td>-6.297857</td>\n",
              "      <td>-5.699578</td>\n",
              "      <td>-5.134220</td>\n",
              "      <td>-3.043005</td>\n",
              "      <td>-4.140237</td>\n",
              "      <td>-5.732683</td>\n",
              "      <td>-7.224386</td>\n",
              "      <td>-7.748537</td>\n",
              "      <td>-7.326008</td>\n",
              "      <td>-5.681371</td>\n",
              "      <td>-5.260024</td>\n",
              "      <td>-5.019885</td>\n",
              "      <td>-4.659293</td>\n",
              "      <td>-4.672777</td>\n",
              "      <td>-6.226246</td>\n",
              "      <td>-6.772582</td>\n",
              "      <td>-6.955715</td>\n",
              "      <td>-7.666700</td>\n",
              "      <td>-9.256272</td>\n",
              "      <td>-9.657508</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.642074</td>\n",
              "      <td>-19.715737</td>\n",
              "      <td>-18.471671</td>\n",
              "      <td>-19.450224</td>\n",
              "      <td>-18.472172</td>\n",
              "      <td>-19.661579</td>\n",
              "      <td>-19.375773</td>\n",
              "      <td>-18.797904</td>\n",
              "      <td>-19.351821</td>\n",
              "      <td>-16.862287</td>\n",
              "      <td>-18.478112</td>\n",
              "      <td>-22.257485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28774</th>\n",
              "      <td>3124</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.236761</td>\n",
              "      <td>-29.579910</td>\n",
              "      <td>-23.170865</td>\n",
              "      <td>-21.261693</td>\n",
              "      <td>-20.623794</td>\n",
              "      <td>-22.057376</td>\n",
              "      <td>-20.219895</td>\n",
              "      <td>-19.747154</td>\n",
              "      <td>-19.017990</td>\n",
              "      <td>-18.630360</td>\n",
              "      <td>-19.946195</td>\n",
              "      <td>-16.869663</td>\n",
              "      <td>-16.964487</td>\n",
              "      <td>-18.406289</td>\n",
              "      <td>-15.617709</td>\n",
              "      <td>-16.363588</td>\n",
              "      <td>-16.796671</td>\n",
              "      <td>-14.649191</td>\n",
              "      <td>-13.788237</td>\n",
              "      <td>-14.807130</td>\n",
              "      <td>-16.805325</td>\n",
              "      <td>-14.539817</td>\n",
              "      <td>-14.673064</td>\n",
              "      <td>-15.700687</td>\n",
              "      <td>-19.022830</td>\n",
              "      <td>-18.554346</td>\n",
              "      <td>-17.055631</td>\n",
              "      <td>-17.149282</td>\n",
              "      <td>-17.204413</td>\n",
              "      <td>-18.017901</td>\n",
              "      <td>-15.639669</td>\n",
              "      <td>...</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>-54.580044</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 217 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0          0          1  ...        213        214        215\n",
              "22678        2158 -19.770191 -17.820446  ...   0.000000   0.000000   0.000000\n",
              "27102        1452 -18.470215 -18.634213  ...   0.000000   0.000000   0.000000\n",
              "3584         3584  -3.463185  -7.545588  ...   0.000000   0.000000   0.000000\n",
              "1888         1888 -23.718474 -20.618072  ...   0.000000   0.000000   0.000000\n",
              "7138         2008   1.776653  -1.903978  ...   0.000000   0.000000   0.000000\n",
              "13134        2874 -18.160437 -16.969181  ...   0.000000   0.000000   0.000000\n",
              "22992        2472   1.497068  -1.872089  ...   0.000000   0.000000   0.000000\n",
              "10397         137 -25.805083 -24.362060  ... -42.601091 -42.601091 -42.601091\n",
              "5550          420 -18.971343 -18.861279  ...   0.000000   0.000000   0.000000\n",
              "28774        3124 -54.580044 -54.580044  ...   0.000000   0.000000   0.000000\n",
              "\n",
              "[10 rows x 217 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2kzXDsgkYOq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "cb90a450-b73e-4409-ed6a-7e25145ec050"
      },
      "source": [
        "# data normalization \n",
        "mean = np.mean(X_train, axis=0)\n",
        "std = np.std(X_train, axis=0)\n",
        "\n",
        "X_train = (X_train - mean)/std\n",
        "X_test = (X_test - mean)/std\n",
        "\n",
        "# Check the dataset now \n",
        "X_train[150:160]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "      <th>180</th>\n",
              "      <th>181</th>\n",
              "      <th>182</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>200</th>\n",
              "      <th>201</th>\n",
              "      <th>202</th>\n",
              "      <th>203</th>\n",
              "      <th>204</th>\n",
              "      <th>205</th>\n",
              "      <th>206</th>\n",
              "      <th>207</th>\n",
              "      <th>208</th>\n",
              "      <th>209</th>\n",
              "      <th>210</th>\n",
              "      <th>211</th>\n",
              "      <th>212</th>\n",
              "      <th>213</th>\n",
              "      <th>214</th>\n",
              "      <th>215</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22678</th>\n",
              "      <td>-0.271252</td>\n",
              "      <td>0.168684</td>\n",
              "      <td>0.269982</td>\n",
              "      <td>0.357674</td>\n",
              "      <td>0.522608</td>\n",
              "      <td>0.471682</td>\n",
              "      <td>0.371220</td>\n",
              "      <td>0.367803</td>\n",
              "      <td>0.350646</td>\n",
              "      <td>0.257892</td>\n",
              "      <td>0.354622</td>\n",
              "      <td>0.457073</td>\n",
              "      <td>0.473369</td>\n",
              "      <td>0.603617</td>\n",
              "      <td>0.601362</td>\n",
              "      <td>0.514713</td>\n",
              "      <td>0.493808</td>\n",
              "      <td>0.330045</td>\n",
              "      <td>0.318789</td>\n",
              "      <td>0.427737</td>\n",
              "      <td>0.327729</td>\n",
              "      <td>0.250236</td>\n",
              "      <td>0.323535</td>\n",
              "      <td>0.543235</td>\n",
              "      <td>0.658744</td>\n",
              "      <td>0.609691</td>\n",
              "      <td>0.663989</td>\n",
              "      <td>0.685690</td>\n",
              "      <td>0.676454</td>\n",
              "      <td>0.617028</td>\n",
              "      <td>0.505549</td>\n",
              "      <td>0.519892</td>\n",
              "      <td>0.547261</td>\n",
              "      <td>0.303226</td>\n",
              "      <td>0.067993</td>\n",
              "      <td>0.205820</td>\n",
              "      <td>0.324208</td>\n",
              "      <td>0.371506</td>\n",
              "      <td>0.420494</td>\n",
              "      <td>0.305310</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895429</td>\n",
              "      <td>0.899126</td>\n",
              "      <td>0.903580</td>\n",
              "      <td>0.873929</td>\n",
              "      <td>0.876673</td>\n",
              "      <td>0.879624</td>\n",
              "      <td>0.851324</td>\n",
              "      <td>0.852089</td>\n",
              "      <td>0.826121</td>\n",
              "      <td>0.826834</td>\n",
              "      <td>0.826852</td>\n",
              "      <td>0.802512</td>\n",
              "      <td>0.801175</td>\n",
              "      <td>0.800675</td>\n",
              "      <td>0.773668</td>\n",
              "      <td>0.773595</td>\n",
              "      <td>0.772818</td>\n",
              "      <td>0.751099</td>\n",
              "      <td>0.750453</td>\n",
              "      <td>0.751024</td>\n",
              "      <td>0.731834</td>\n",
              "      <td>0.731721</td>\n",
              "      <td>0.731378</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.714996</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>0.691590</td>\n",
              "      <td>0.692605</td>\n",
              "      <td>0.671934</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.651529</td>\n",
              "      <td>0.650073</td>\n",
              "      <td>0.649610</td>\n",
              "      <td>0.630316</td>\n",
              "      <td>0.629083</td>\n",
              "      <td>0.629010</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27102</th>\n",
              "      <td>-0.747240</td>\n",
              "      <td>0.244682</td>\n",
              "      <td>0.220788</td>\n",
              "      <td>0.346532</td>\n",
              "      <td>0.460782</td>\n",
              "      <td>0.439069</td>\n",
              "      <td>0.455779</td>\n",
              "      <td>0.485186</td>\n",
              "      <td>0.607414</td>\n",
              "      <td>0.614291</td>\n",
              "      <td>0.562405</td>\n",
              "      <td>0.455044</td>\n",
              "      <td>0.335497</td>\n",
              "      <td>0.377136</td>\n",
              "      <td>0.331816</td>\n",
              "      <td>0.330899</td>\n",
              "      <td>0.356020</td>\n",
              "      <td>0.481292</td>\n",
              "      <td>0.520249</td>\n",
              "      <td>0.440181</td>\n",
              "      <td>0.444031</td>\n",
              "      <td>0.501741</td>\n",
              "      <td>0.388443</td>\n",
              "      <td>0.262964</td>\n",
              "      <td>0.297632</td>\n",
              "      <td>0.375768</td>\n",
              "      <td>0.286544</td>\n",
              "      <td>0.355963</td>\n",
              "      <td>0.341793</td>\n",
              "      <td>0.344018</td>\n",
              "      <td>0.494345</td>\n",
              "      <td>0.535904</td>\n",
              "      <td>0.552268</td>\n",
              "      <td>0.580210</td>\n",
              "      <td>0.693799</td>\n",
              "      <td>0.656872</td>\n",
              "      <td>0.538620</td>\n",
              "      <td>0.530656</td>\n",
              "      <td>0.677042</td>\n",
              "      <td>0.501449</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.719947</td>\n",
              "      <td>-0.709772</td>\n",
              "      <td>-0.699310</td>\n",
              "      <td>-0.726850</td>\n",
              "      <td>-0.718438</td>\n",
              "      <td>-0.710688</td>\n",
              "      <td>-0.741060</td>\n",
              "      <td>-0.739054</td>\n",
              "      <td>-0.768456</td>\n",
              "      <td>-0.767533</td>\n",
              "      <td>-0.767299</td>\n",
              "      <td>-0.798283</td>\n",
              "      <td>-0.798926</td>\n",
              "      <td>-0.798968</td>\n",
              "      <td>-0.833700</td>\n",
              "      <td>-0.399762</td>\n",
              "      <td>-0.016640</td>\n",
              "      <td>0.083214</td>\n",
              "      <td>0.038042</td>\n",
              "      <td>0.060930</td>\n",
              "      <td>0.731834</td>\n",
              "      <td>0.731721</td>\n",
              "      <td>0.731378</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.714996</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>0.691590</td>\n",
              "      <td>0.692605</td>\n",
              "      <td>0.671934</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.651529</td>\n",
              "      <td>0.650073</td>\n",
              "      <td>0.649610</td>\n",
              "      <td>0.630316</td>\n",
              "      <td>0.629083</td>\n",
              "      <td>0.629010</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3584</th>\n",
              "      <td>0.690163</td>\n",
              "      <td>1.122015</td>\n",
              "      <td>0.891119</td>\n",
              "      <td>0.504571</td>\n",
              "      <td>0.453558</td>\n",
              "      <td>0.461922</td>\n",
              "      <td>0.449892</td>\n",
              "      <td>0.481380</td>\n",
              "      <td>0.432420</td>\n",
              "      <td>0.332285</td>\n",
              "      <td>0.358671</td>\n",
              "      <td>0.844755</td>\n",
              "      <td>0.907107</td>\n",
              "      <td>0.513308</td>\n",
              "      <td>0.661164</td>\n",
              "      <td>0.686994</td>\n",
              "      <td>0.680038</td>\n",
              "      <td>0.899600</td>\n",
              "      <td>1.103239</td>\n",
              "      <td>1.001079</td>\n",
              "      <td>0.521151</td>\n",
              "      <td>0.431304</td>\n",
              "      <td>0.403043</td>\n",
              "      <td>0.524344</td>\n",
              "      <td>0.522618</td>\n",
              "      <td>0.307191</td>\n",
              "      <td>0.118507</td>\n",
              "      <td>0.309715</td>\n",
              "      <td>0.182623</td>\n",
              "      <td>0.184627</td>\n",
              "      <td>0.214621</td>\n",
              "      <td>-0.024354</td>\n",
              "      <td>0.081889</td>\n",
              "      <td>0.355640</td>\n",
              "      <td>0.295863</td>\n",
              "      <td>0.387416</td>\n",
              "      <td>0.399534</td>\n",
              "      <td>0.405992</td>\n",
              "      <td>0.723581</td>\n",
              "      <td>0.796279</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895429</td>\n",
              "      <td>0.899126</td>\n",
              "      <td>0.903580</td>\n",
              "      <td>0.873929</td>\n",
              "      <td>0.876673</td>\n",
              "      <td>0.879624</td>\n",
              "      <td>0.851324</td>\n",
              "      <td>0.852089</td>\n",
              "      <td>0.826121</td>\n",
              "      <td>0.826834</td>\n",
              "      <td>0.826852</td>\n",
              "      <td>0.802512</td>\n",
              "      <td>0.801175</td>\n",
              "      <td>0.800675</td>\n",
              "      <td>0.773668</td>\n",
              "      <td>0.773595</td>\n",
              "      <td>0.772818</td>\n",
              "      <td>0.751099</td>\n",
              "      <td>0.750453</td>\n",
              "      <td>0.751024</td>\n",
              "      <td>0.731834</td>\n",
              "      <td>0.731721</td>\n",
              "      <td>0.731378</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.714996</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>0.691590</td>\n",
              "      <td>0.692605</td>\n",
              "      <td>0.671934</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.651529</td>\n",
              "      <td>0.650073</td>\n",
              "      <td>0.649610</td>\n",
              "      <td>0.630316</td>\n",
              "      <td>0.629083</td>\n",
              "      <td>0.629010</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1888</th>\n",
              "      <td>-0.453287</td>\n",
              "      <td>-0.062138</td>\n",
              "      <td>0.100859</td>\n",
              "      <td>0.317542</td>\n",
              "      <td>0.222112</td>\n",
              "      <td>0.282278</td>\n",
              "      <td>0.373717</td>\n",
              "      <td>0.413706</td>\n",
              "      <td>0.627864</td>\n",
              "      <td>0.570568</td>\n",
              "      <td>0.582244</td>\n",
              "      <td>0.637039</td>\n",
              "      <td>0.664100</td>\n",
              "      <td>0.695874</td>\n",
              "      <td>0.636204</td>\n",
              "      <td>0.623278</td>\n",
              "      <td>0.592197</td>\n",
              "      <td>0.578823</td>\n",
              "      <td>0.529230</td>\n",
              "      <td>0.364323</td>\n",
              "      <td>0.194393</td>\n",
              "      <td>0.199689</td>\n",
              "      <td>0.207561</td>\n",
              "      <td>0.145731</td>\n",
              "      <td>0.446840</td>\n",
              "      <td>0.532963</td>\n",
              "      <td>0.593822</td>\n",
              "      <td>0.554791</td>\n",
              "      <td>0.375039</td>\n",
              "      <td>0.108977</td>\n",
              "      <td>0.153264</td>\n",
              "      <td>0.105977</td>\n",
              "      <td>0.066860</td>\n",
              "      <td>0.041034</td>\n",
              "      <td>0.114815</td>\n",
              "      <td>0.391149</td>\n",
              "      <td>0.270599</td>\n",
              "      <td>-0.097538</td>\n",
              "      <td>-0.071720</td>\n",
              "      <td>0.014564</td>\n",
              "      <td>...</td>\n",
              "      <td>0.144123</td>\n",
              "      <td>0.191851</td>\n",
              "      <td>0.206149</td>\n",
              "      <td>0.118488</td>\n",
              "      <td>0.066720</td>\n",
              "      <td>0.090629</td>\n",
              "      <td>0.032530</td>\n",
              "      <td>-0.034645</td>\n",
              "      <td>0.826121</td>\n",
              "      <td>0.826834</td>\n",
              "      <td>0.826852</td>\n",
              "      <td>0.802512</td>\n",
              "      <td>0.801175</td>\n",
              "      <td>0.800675</td>\n",
              "      <td>0.773668</td>\n",
              "      <td>0.773595</td>\n",
              "      <td>0.772818</td>\n",
              "      <td>0.751099</td>\n",
              "      <td>0.750453</td>\n",
              "      <td>0.751024</td>\n",
              "      <td>0.731834</td>\n",
              "      <td>0.731721</td>\n",
              "      <td>0.731378</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.714996</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>0.691590</td>\n",
              "      <td>0.692605</td>\n",
              "      <td>0.671934</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.651529</td>\n",
              "      <td>0.650073</td>\n",
              "      <td>0.649610</td>\n",
              "      <td>0.630316</td>\n",
              "      <td>0.629083</td>\n",
              "      <td>0.629010</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7138</th>\n",
              "      <td>-0.372383</td>\n",
              "      <td>1.428343</td>\n",
              "      <td>1.232166</td>\n",
              "      <td>0.668953</td>\n",
              "      <td>0.797420</td>\n",
              "      <td>0.822246</td>\n",
              "      <td>0.857970</td>\n",
              "      <td>0.685923</td>\n",
              "      <td>0.587961</td>\n",
              "      <td>0.525454</td>\n",
              "      <td>0.492895</td>\n",
              "      <td>0.635384</td>\n",
              "      <td>0.584335</td>\n",
              "      <td>0.564018</td>\n",
              "      <td>0.404349</td>\n",
              "      <td>0.305566</td>\n",
              "      <td>0.421078</td>\n",
              "      <td>0.484389</td>\n",
              "      <td>0.358699</td>\n",
              "      <td>0.278750</td>\n",
              "      <td>0.414657</td>\n",
              "      <td>0.698835</td>\n",
              "      <td>0.730156</td>\n",
              "      <td>0.846347</td>\n",
              "      <td>0.933338</td>\n",
              "      <td>0.960726</td>\n",
              "      <td>0.998930</td>\n",
              "      <td>0.892443</td>\n",
              "      <td>0.946680</td>\n",
              "      <td>0.859697</td>\n",
              "      <td>0.706582</td>\n",
              "      <td>0.734024</td>\n",
              "      <td>0.668858</td>\n",
              "      <td>0.651943</td>\n",
              "      <td>0.641790</td>\n",
              "      <td>0.806038</td>\n",
              "      <td>0.816847</td>\n",
              "      <td>0.723619</td>\n",
              "      <td>1.032745</td>\n",
              "      <td>1.072320</td>\n",
              "      <td>...</td>\n",
              "      <td>0.189175</td>\n",
              "      <td>0.252278</td>\n",
              "      <td>0.335502</td>\n",
              "      <td>0.324467</td>\n",
              "      <td>0.236228</td>\n",
              "      <td>0.270026</td>\n",
              "      <td>0.169834</td>\n",
              "      <td>0.214228</td>\n",
              "      <td>0.222803</td>\n",
              "      <td>0.207027</td>\n",
              "      <td>0.198418</td>\n",
              "      <td>0.155155</td>\n",
              "      <td>0.111810</td>\n",
              "      <td>-0.024537</td>\n",
              "      <td>0.773668</td>\n",
              "      <td>0.773595</td>\n",
              "      <td>0.772818</td>\n",
              "      <td>0.751099</td>\n",
              "      <td>0.750453</td>\n",
              "      <td>0.751024</td>\n",
              "      <td>0.731834</td>\n",
              "      <td>0.731721</td>\n",
              "      <td>0.731378</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.714996</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>0.691590</td>\n",
              "      <td>0.692605</td>\n",
              "      <td>0.671934</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.651529</td>\n",
              "      <td>0.650073</td>\n",
              "      <td>0.649610</td>\n",
              "      <td>0.630316</td>\n",
              "      <td>0.629083</td>\n",
              "      <td>0.629010</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13134</th>\n",
              "      <td>0.211478</td>\n",
              "      <td>0.262792</td>\n",
              "      <td>0.321442</td>\n",
              "      <td>0.392761</td>\n",
              "      <td>0.413833</td>\n",
              "      <td>0.404413</td>\n",
              "      <td>0.417050</td>\n",
              "      <td>0.420754</td>\n",
              "      <td>0.537461</td>\n",
              "      <td>0.580228</td>\n",
              "      <td>0.432966</td>\n",
              "      <td>0.375295</td>\n",
              "      <td>0.395512</td>\n",
              "      <td>0.237955</td>\n",
              "      <td>0.108781</td>\n",
              "      <td>0.183632</td>\n",
              "      <td>0.335159</td>\n",
              "      <td>0.533564</td>\n",
              "      <td>0.393282</td>\n",
              "      <td>0.230150</td>\n",
              "      <td>0.232580</td>\n",
              "      <td>0.120729</td>\n",
              "      <td>0.137128</td>\n",
              "      <td>0.144642</td>\n",
              "      <td>0.181167</td>\n",
              "      <td>0.297271</td>\n",
              "      <td>0.384859</td>\n",
              "      <td>0.245809</td>\n",
              "      <td>0.286857</td>\n",
              "      <td>0.338767</td>\n",
              "      <td>0.161659</td>\n",
              "      <td>0.057382</td>\n",
              "      <td>0.393864</td>\n",
              "      <td>0.389629</td>\n",
              "      <td>0.173880</td>\n",
              "      <td>0.194230</td>\n",
              "      <td>0.254070</td>\n",
              "      <td>0.092685</td>\n",
              "      <td>-0.038070</td>\n",
              "      <td>0.140929</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.115308</td>\n",
              "      <td>-1.103548</td>\n",
              "      <td>-1.091615</td>\n",
              "      <td>-1.118639</td>\n",
              "      <td>-1.108840</td>\n",
              "      <td>-1.099915</td>\n",
              "      <td>-1.130794</td>\n",
              "      <td>-1.128484</td>\n",
              "      <td>-1.158727</td>\n",
              "      <td>-1.157753</td>\n",
              "      <td>-1.157466</td>\n",
              "      <td>-1.190077</td>\n",
              "      <td>-1.190550</td>\n",
              "      <td>-1.190479</td>\n",
              "      <td>0.773668</td>\n",
              "      <td>0.773595</td>\n",
              "      <td>0.772818</td>\n",
              "      <td>0.751099</td>\n",
              "      <td>0.750453</td>\n",
              "      <td>0.751024</td>\n",
              "      <td>0.731834</td>\n",
              "      <td>0.731721</td>\n",
              "      <td>0.731378</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.714996</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>0.691590</td>\n",
              "      <td>0.692605</td>\n",
              "      <td>0.671934</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.651529</td>\n",
              "      <td>0.650073</td>\n",
              "      <td>0.649610</td>\n",
              "      <td>0.630316</td>\n",
              "      <td>0.629083</td>\n",
              "      <td>0.629010</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22992</th>\n",
              "      <td>-0.059552</td>\n",
              "      <td>1.411999</td>\n",
              "      <td>1.234093</td>\n",
              "      <td>1.170611</td>\n",
              "      <td>1.073103</td>\n",
              "      <td>1.057451</td>\n",
              "      <td>1.197875</td>\n",
              "      <td>1.293992</td>\n",
              "      <td>1.234818</td>\n",
              "      <td>1.193204</td>\n",
              "      <td>1.346181</td>\n",
              "      <td>1.388364</td>\n",
              "      <td>1.268965</td>\n",
              "      <td>1.194088</td>\n",
              "      <td>1.330129</td>\n",
              "      <td>1.193026</td>\n",
              "      <td>0.921586</td>\n",
              "      <td>0.835310</td>\n",
              "      <td>0.809237</td>\n",
              "      <td>0.954245</td>\n",
              "      <td>0.871820</td>\n",
              "      <td>1.031041</td>\n",
              "      <td>0.950681</td>\n",
              "      <td>0.749588</td>\n",
              "      <td>0.928422</td>\n",
              "      <td>0.880918</td>\n",
              "      <td>0.929347</td>\n",
              "      <td>0.814675</td>\n",
              "      <td>0.898373</td>\n",
              "      <td>0.970206</td>\n",
              "      <td>0.966247</td>\n",
              "      <td>0.943891</td>\n",
              "      <td>1.095479</td>\n",
              "      <td>1.058948</td>\n",
              "      <td>1.167465</td>\n",
              "      <td>1.157454</td>\n",
              "      <td>1.192476</td>\n",
              "      <td>1.300941</td>\n",
              "      <td>1.349165</td>\n",
              "      <td>1.198215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895429</td>\n",
              "      <td>0.899126</td>\n",
              "      <td>0.903580</td>\n",
              "      <td>0.873929</td>\n",
              "      <td>0.876673</td>\n",
              "      <td>0.879624</td>\n",
              "      <td>0.851324</td>\n",
              "      <td>0.852089</td>\n",
              "      <td>0.826121</td>\n",
              "      <td>0.826834</td>\n",
              "      <td>0.826852</td>\n",
              "      <td>0.802512</td>\n",
              "      <td>0.801175</td>\n",
              "      <td>0.800675</td>\n",
              "      <td>0.773668</td>\n",
              "      <td>0.773595</td>\n",
              "      <td>0.772818</td>\n",
              "      <td>0.751099</td>\n",
              "      <td>0.750453</td>\n",
              "      <td>0.751024</td>\n",
              "      <td>0.731834</td>\n",
              "      <td>0.731721</td>\n",
              "      <td>0.731378</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.714996</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>0.691590</td>\n",
              "      <td>0.692605</td>\n",
              "      <td>0.671934</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.651529</td>\n",
              "      <td>0.650073</td>\n",
              "      <td>0.649610</td>\n",
              "      <td>0.630316</td>\n",
              "      <td>0.629083</td>\n",
              "      <td>0.629010</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10397</th>\n",
              "      <td>-1.633819</td>\n",
              "      <td>-0.184125</td>\n",
              "      <td>-0.125473</td>\n",
              "      <td>0.195526</td>\n",
              "      <td>0.500583</td>\n",
              "      <td>0.451884</td>\n",
              "      <td>0.359101</td>\n",
              "      <td>0.394391</td>\n",
              "      <td>0.542582</td>\n",
              "      <td>0.607983</td>\n",
              "      <td>0.568091</td>\n",
              "      <td>0.492606</td>\n",
              "      <td>0.368759</td>\n",
              "      <td>0.390806</td>\n",
              "      <td>0.330668</td>\n",
              "      <td>0.303606</td>\n",
              "      <td>0.575227</td>\n",
              "      <td>0.747969</td>\n",
              "      <td>0.674202</td>\n",
              "      <td>0.437324</td>\n",
              "      <td>0.409142</td>\n",
              "      <td>0.261739</td>\n",
              "      <td>0.255205</td>\n",
              "      <td>0.010142</td>\n",
              "      <td>-0.205185</td>\n",
              "      <td>-0.290954</td>\n",
              "      <td>-0.033407</td>\n",
              "      <td>0.224763</td>\n",
              "      <td>0.443869</td>\n",
              "      <td>0.412833</td>\n",
              "      <td>0.335210</td>\n",
              "      <td>0.204061</td>\n",
              "      <td>0.144949</td>\n",
              "      <td>-0.009087</td>\n",
              "      <td>-0.028593</td>\n",
              "      <td>0.039488</td>\n",
              "      <td>0.093377</td>\n",
              "      <td>0.255522</td>\n",
              "      <td>0.497954</td>\n",
              "      <td>0.508267</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.843676</td>\n",
              "      <td>-0.833005</td>\n",
              "      <td>-0.822083</td>\n",
              "      <td>-0.849461</td>\n",
              "      <td>-0.840615</td>\n",
              "      <td>-0.832497</td>\n",
              "      <td>-0.863028</td>\n",
              "      <td>-0.860927</td>\n",
              "      <td>-0.890592</td>\n",
              "      <td>-0.889653</td>\n",
              "      <td>-0.889403</td>\n",
              "      <td>-0.920896</td>\n",
              "      <td>-0.921485</td>\n",
              "      <td>-0.921492</td>\n",
              "      <td>-0.956815</td>\n",
              "      <td>-0.957582</td>\n",
              "      <td>-0.959046</td>\n",
              "      <td>-0.991003</td>\n",
              "      <td>-0.992645</td>\n",
              "      <td>-0.992020</td>\n",
              "      <td>-1.018335</td>\n",
              "      <td>-1.019140</td>\n",
              "      <td>-1.020453</td>\n",
              "      <td>-1.046574</td>\n",
              "      <td>-1.046218</td>\n",
              "      <td>-1.046620</td>\n",
              "      <td>-1.083542</td>\n",
              "      <td>-1.083836</td>\n",
              "      <td>-1.083028</td>\n",
              "      <td>-1.119059</td>\n",
              "      <td>-1.122289</td>\n",
              "      <td>-1.160995</td>\n",
              "      <td>-1.166395</td>\n",
              "      <td>-1.170941</td>\n",
              "      <td>-1.212636</td>\n",
              "      <td>-1.217801</td>\n",
              "      <td>-1.220303</td>\n",
              "      <td>-1.252587</td>\n",
              "      <td>-1.261383</td>\n",
              "      <td>-1.260946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5550</th>\n",
              "      <td>-1.443019</td>\n",
              "      <td>0.215386</td>\n",
              "      <td>0.207061</td>\n",
              "      <td>0.209426</td>\n",
              "      <td>0.224130</td>\n",
              "      <td>0.344813</td>\n",
              "      <td>0.230612</td>\n",
              "      <td>0.210614</td>\n",
              "      <td>0.260740</td>\n",
              "      <td>0.157655</td>\n",
              "      <td>0.234824</td>\n",
              "      <td>0.890842</td>\n",
              "      <td>1.153522</td>\n",
              "      <td>1.070843</td>\n",
              "      <td>0.984451</td>\n",
              "      <td>1.022364</td>\n",
              "      <td>0.972132</td>\n",
              "      <td>0.839115</td>\n",
              "      <td>0.854796</td>\n",
              "      <td>0.886778</td>\n",
              "      <td>0.970275</td>\n",
              "      <td>1.009462</td>\n",
              "      <td>1.047774</td>\n",
              "      <td>1.193792</td>\n",
              "      <td>1.120345</td>\n",
              "      <td>1.011351</td>\n",
              "      <td>0.908645</td>\n",
              "      <td>0.874057</td>\n",
              "      <td>0.909603</td>\n",
              "      <td>1.042299</td>\n",
              "      <td>1.090424</td>\n",
              "      <td>1.127417</td>\n",
              "      <td>1.177459</td>\n",
              "      <td>1.198478</td>\n",
              "      <td>1.085971</td>\n",
              "      <td>1.054130</td>\n",
              "      <td>1.051049</td>\n",
              "      <td>0.994872</td>\n",
              "      <td>0.849829</td>\n",
              "      <td>0.817878</td>\n",
              "      <td>...</td>\n",
              "      <td>0.134404</td>\n",
              "      <td>0.097498</td>\n",
              "      <td>0.155339</td>\n",
              "      <td>0.087087</td>\n",
              "      <td>0.132043</td>\n",
              "      <td>0.089433</td>\n",
              "      <td>0.071605</td>\n",
              "      <td>0.096214</td>\n",
              "      <td>0.046293</td>\n",
              "      <td>0.147417</td>\n",
              "      <td>0.082431</td>\n",
              "      <td>-0.097905</td>\n",
              "      <td>0.801175</td>\n",
              "      <td>0.800675</td>\n",
              "      <td>0.773668</td>\n",
              "      <td>0.773595</td>\n",
              "      <td>0.772818</td>\n",
              "      <td>0.751099</td>\n",
              "      <td>0.750453</td>\n",
              "      <td>0.751024</td>\n",
              "      <td>0.731834</td>\n",
              "      <td>0.731721</td>\n",
              "      <td>0.731378</td>\n",
              "      <td>0.714556</td>\n",
              "      <td>0.714996</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.691246</td>\n",
              "      <td>0.691590</td>\n",
              "      <td>0.692605</td>\n",
              "      <td>0.671934</td>\n",
              "      <td>0.671300</td>\n",
              "      <td>0.651529</td>\n",
              "      <td>0.650073</td>\n",
              "      <td>0.649610</td>\n",
              "      <td>0.630316</td>\n",
              "      <td>0.629083</td>\n",
              "      <td>0.629010</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28774</th>\n",
              "      <td>0.380029</td>\n",
              "      <td>-1.866350</td>\n",
              "      <td>-1.952213</td>\n",
              "      <td>-2.007248</td>\n",
              "      <td>-2.046816</td>\n",
              "      <td>-2.102075</td>\n",
              "      <td>-2.153468</td>\n",
              "      <td>-2.211259</td>\n",
              "      <td>-2.270189</td>\n",
              "      <td>-2.312339</td>\n",
              "      <td>-0.621525</td>\n",
              "      <td>-0.181322</td>\n",
              "      <td>-0.052248</td>\n",
              "      <td>-0.012913</td>\n",
              "      <td>-0.118406</td>\n",
              "      <td>0.005204</td>\n",
              "      <td>0.037162</td>\n",
              "      <td>0.086296</td>\n",
              "      <td>0.112401</td>\n",
              "      <td>0.016799</td>\n",
              "      <td>0.229916</td>\n",
              "      <td>0.219695</td>\n",
              "      <td>0.115192</td>\n",
              "      <td>0.308111</td>\n",
              "      <td>0.254559</td>\n",
              "      <td>0.221318</td>\n",
              "      <td>0.372628</td>\n",
              "      <td>0.432555</td>\n",
              "      <td>0.355395</td>\n",
              "      <td>0.200565</td>\n",
              "      <td>0.366526</td>\n",
              "      <td>0.349077</td>\n",
              "      <td>0.256208</td>\n",
              "      <td>-0.041080</td>\n",
              "      <td>-0.015240</td>\n",
              "      <td>0.105904</td>\n",
              "      <td>0.085047</td>\n",
              "      <td>0.069074</td>\n",
              "      <td>-0.013695</td>\n",
              "      <td>0.220380</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.332693</td>\n",
              "      <td>-1.320060</td>\n",
              "      <td>-1.307320</td>\n",
              "      <td>-1.334059</td>\n",
              "      <td>-1.323497</td>\n",
              "      <td>-1.313926</td>\n",
              "      <td>-1.345084</td>\n",
              "      <td>-1.342608</td>\n",
              "      <td>-1.373312</td>\n",
              "      <td>-1.372310</td>\n",
              "      <td>-1.371994</td>\n",
              "      <td>-1.405499</td>\n",
              "      <td>-1.405878</td>\n",
              "      <td>-1.405746</td>\n",
              "      <td>-1.443408</td>\n",
              "      <td>-1.444370</td>\n",
              "      <td>-1.446027</td>\n",
              "      <td>-1.480863</td>\n",
              "      <td>-1.482785</td>\n",
              "      <td>-1.482144</td>\n",
              "      <td>-1.510463</td>\n",
              "      <td>-1.511463</td>\n",
              "      <td>-1.513048</td>\n",
              "      <td>-1.541785</td>\n",
              "      <td>-1.541452</td>\n",
              "      <td>-1.541705</td>\n",
              "      <td>-1.582593</td>\n",
              "      <td>-1.583066</td>\n",
              "      <td>-1.582316</td>\n",
              "      <td>-1.622667</td>\n",
              "      <td>-1.626626</td>\n",
              "      <td>-1.670657</td>\n",
              "      <td>-1.677166</td>\n",
              "      <td>-1.682860</td>\n",
              "      <td>-1.730853</td>\n",
              "      <td>-1.737124</td>\n",
              "      <td>-1.740310</td>\n",
              "      <td>0.614118</td>\n",
              "      <td>0.609028</td>\n",
              "      <td>0.605407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 217 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0         0         1  ...       213       214       215\n",
              "22678   -0.271252  0.168684  0.269982  ...  0.614118  0.609028  0.605407\n",
              "27102   -0.747240  0.244682  0.220788  ...  0.614118  0.609028  0.605407\n",
              "3584     0.690163  1.122015  0.891119  ...  0.614118  0.609028  0.605407\n",
              "1888    -0.453287 -0.062138  0.100859  ...  0.614118  0.609028  0.605407\n",
              "7138    -0.372383  1.428343  1.232166  ...  0.614118  0.609028  0.605407\n",
              "13134    0.211478  0.262792  0.321442  ...  0.614118  0.609028  0.605407\n",
              "22992   -0.059552  1.411999  1.234093  ...  0.614118  0.609028  0.605407\n",
              "10397   -1.633819 -0.184125 -0.125473  ... -1.252587 -1.261383 -1.260946\n",
              "5550    -1.443019  0.215386  0.207061  ...  0.614118  0.609028  0.605407\n",
              "28774    0.380029 -1.866350 -1.952213  ...  0.614118  0.609028  0.605407\n",
              "\n",
              "[10 rows x 217 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK2J7XwikYOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "de2b7bac-4498-407e-b31f-220ed34680f2"
      },
      "source": [
        "#steps to get it into the correct format for Keras \n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# one hot encode the target \n",
        "lb = LabelEncoder()\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "y_test = np_utils.to_categorical(lb.fit_transform(y_test))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(lb.classes_)\n",
        "\n",
        "# Pickel the lb object for future use \n",
        "filename = 'labels'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(lb,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24624, 217)\n",
            "['male_angry' 'male_disgust' 'male_fear' 'male_happy' 'male_neutral'\n",
            " 'male_sad' 'male_surprise']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOH7IykrkYO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "21c9cf89-0d8a-49bc-d8eb-d182c30dc51a"
      },
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "X_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24624, 217, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX2XrOqXkYO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d155f25a-fd71-4202-c215-9c9b72b9e3f9"
      },
      "source": [
        "# New model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(256, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(8)))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128)) # Target class number\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128)) # Target class number\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128)) # Target class number\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128)) # Target class number\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(7)) # Target class number\n",
        "model.add(Activation('softmax'))\n",
        "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_17 (Conv1D)           (None, 217, 256)          2304      \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 217, 256)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 217, 256)          524544    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 217, 256)          1024      \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 217, 256)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 217, 256)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1 (None, 27, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 27, 128)           262272    \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 27, 128)           131200    \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 27, 128)           131200    \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 27, 128)           131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 27, 128)           512       \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 3, 128)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 3, 64)             65600     \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 3, 64)             0         \n",
            "_________________________________________________________________\n",
            "conv1d_24 (Conv1D)           (None, 3, 64)             32832     \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 3, 64)             0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 192)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               24704     \n",
            "_________________________________________________________________\n",
            "activation_33 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_34 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_35 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_36 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 7)                 903       \n",
            "_________________________________________________________________\n",
            "activation_37 (Activation)   (None, 7)                 0         \n",
            "=================================================================\n",
            "Total params: 1,357,831\n",
            "Trainable params: 1,357,063\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ajY0NkYkYPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6202a04c-14d6-409f-df0f-7d0af091ff50"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "model_history=model.fit(X_train, y_train, batch_size=10, epochs=200, validation_data=(X_test, y_test),verbose=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24624 samples, validate on 6156 samples\n",
            "Epoch 1/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.7815 - accuracy: 0.2564 - val_loss: 1.7186 - val_accuracy: 0.3012\n",
            "Epoch 2/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.6872 - accuracy: 0.3136 - val_loss: 1.6998 - val_accuracy: 0.3127\n",
            "Epoch 3/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.6577 - accuracy: 0.3280 - val_loss: 1.6512 - val_accuracy: 0.3345\n",
            "Epoch 4/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.6343 - accuracy: 0.3402 - val_loss: 1.6951 - val_accuracy: 0.3002\n",
            "Epoch 5/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.6124 - accuracy: 0.3490 - val_loss: 1.6546 - val_accuracy: 0.3324\n",
            "Epoch 6/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.5935 - accuracy: 0.3581 - val_loss: 1.6297 - val_accuracy: 0.3441\n",
            "Epoch 7/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.5734 - accuracy: 0.3661 - val_loss: 1.6853 - val_accuracy: 0.3250\n",
            "Epoch 8/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.5518 - accuracy: 0.3771 - val_loss: 1.6648 - val_accuracy: 0.3317\n",
            "Epoch 9/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.5377 - accuracy: 0.3819 - val_loss: 1.6377 - val_accuracy: 0.3294\n",
            "Epoch 10/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.5200 - accuracy: 0.3869 - val_loss: 1.5759 - val_accuracy: 0.3614\n",
            "Epoch 11/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.5043 - accuracy: 0.3935 - val_loss: 1.5955 - val_accuracy: 0.3559\n",
            "Epoch 12/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.4863 - accuracy: 0.4036 - val_loss: 1.5623 - val_accuracy: 0.3702\n",
            "Epoch 13/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.4758 - accuracy: 0.4075 - val_loss: 1.5738 - val_accuracy: 0.3566\n",
            "Epoch 14/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.4579 - accuracy: 0.4137 - val_loss: 1.6067 - val_accuracy: 0.3380\n",
            "Epoch 15/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.4472 - accuracy: 0.4214 - val_loss: 1.5809 - val_accuracy: 0.3691\n",
            "Epoch 16/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.4330 - accuracy: 0.4274 - val_loss: 1.5609 - val_accuracy: 0.3700\n",
            "Epoch 17/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.4219 - accuracy: 0.4299 - val_loss: 1.5137 - val_accuracy: 0.3886\n",
            "Epoch 18/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.4177 - accuracy: 0.4340 - val_loss: 1.5527 - val_accuracy: 0.3813\n",
            "Epoch 19/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.3970 - accuracy: 0.4417 - val_loss: 1.5560 - val_accuracy: 0.3780\n",
            "Epoch 20/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.3838 - accuracy: 0.4468 - val_loss: 1.4868 - val_accuracy: 0.3962\n",
            "Epoch 21/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.3686 - accuracy: 0.4542 - val_loss: 1.5740 - val_accuracy: 0.3707\n",
            "Epoch 22/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 1.3601 - accuracy: 0.4581 - val_loss: 1.5119 - val_accuracy: 0.3913\n",
            "Epoch 23/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.3507 - accuracy: 0.4659 - val_loss: 1.5781 - val_accuracy: 0.3696\n",
            "Epoch 24/200\n",
            "24600/24624 [============================>.] - ETA: 0s - loss: 1.3422 - accuracy: 0.4724Epoch 25/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.3251 - accuracy: 0.4778 - val_loss: 1.5142 - val_accuracy: 0.3900\n",
            "Epoch 26/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 1.3155 - accuracy: 0.4766 - val_loss: 1.4662 - val_accuracy: 0.4175\n",
            "Epoch 27/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 1.3010 - accuracy: 0.4859 - val_loss: 1.4311 - val_accuracy: 0.4331\n",
            "Epoch 28/200\n",
            "24610/24624 [============================>.] - ETA: 0s - loss: 1.2984 - accuracy: 0.4849Epoch 29/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 1.2823 - accuracy: 0.4944 - val_loss: 1.5366 - val_accuracy: 0.3929\n",
            "Epoch 30/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 1.2751 - accuracy: 0.4956 - val_loss: 1.4836 - val_accuracy: 0.4154\n",
            "Epoch 31/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 1.2624 - accuracy: 0.5047 - val_loss: 1.4895 - val_accuracy: 0.4069\n",
            "Epoch 32/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.2599 - accuracy: 0.5006 - val_loss: 1.5129 - val_accuracy: 0.3981\n",
            "Epoch 33/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.2533 - accuracy: 0.5036 - val_loss: 1.4936 - val_accuracy: 0.4037\n",
            "Epoch 34/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.2466 - accuracy: 0.5107 - val_loss: 1.4649 - val_accuracy: 0.4072\n",
            "Epoch 35/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.2302 - accuracy: 0.5125 - val_loss: 1.4270 - val_accuracy: 0.4311\n",
            "Epoch 36/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.2266 - accuracy: 0.5205 - val_loss: 1.4476 - val_accuracy: 0.4324\n",
            "Epoch 37/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.2128 - accuracy: 0.5235 - val_loss: 1.4695 - val_accuracy: 0.4118\n",
            "Epoch 38/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.2057 - accuracy: 0.5232 - val_loss: 1.4411 - val_accuracy: 0.4365\n",
            "Epoch 39/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.1911 - accuracy: 0.5330 - val_loss: 1.5718 - val_accuracy: 0.3957\n",
            "Epoch 40/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.2033 - accuracy: 0.5264 - val_loss: 1.4021 - val_accuracy: 0.4519\n",
            "Epoch 41/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.1804 - accuracy: 0.5396 - val_loss: 1.4368 - val_accuracy: 0.4225\n",
            "Epoch 42/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.1674 - accuracy: 0.5409 - val_loss: 1.3795 - val_accuracy: 0.4578\n",
            "Epoch 43/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.1621 - accuracy: 0.5452 - val_loss: 1.3983 - val_accuracy: 0.4498\n",
            "Epoch 44/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.1520 - accuracy: 0.5515 - val_loss: 1.4572 - val_accuracy: 0.4238\n",
            "Epoch 45/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.1565 - accuracy: 0.5504 - val_loss: 1.3831 - val_accuracy: 0.4615\n",
            "Epoch 46/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 1.1409 - accuracy: 0.5562 - val_loss: 1.4485 - val_accuracy: 0.4339\n",
            "Epoch 47/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.1195 - accuracy: 0.5660 - val_loss: 1.4236 - val_accuracy: 0.4444\n",
            "Epoch 48/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.1158 - accuracy: 0.5672 - val_loss: 1.4952 - val_accuracy: 0.4196\n",
            "Epoch 49/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.1080 - accuracy: 0.5702 - val_loss: 1.4862 - val_accuracy: 0.4274\n",
            "Epoch 50/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0976 - accuracy: 0.5774 - val_loss: 1.4129 - val_accuracy: 0.4630\n",
            "Epoch 51/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0984 - accuracy: 0.5737 - val_loss: 1.4201 - val_accuracy: 0.4483\n",
            "Epoch 52/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0859 - accuracy: 0.5841 - val_loss: 1.4576 - val_accuracy: 0.4444\n",
            "Epoch 53/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0747 - accuracy: 0.5869 - val_loss: 1.3742 - val_accuracy: 0.4610\n",
            "Epoch 54/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0613 - accuracy: 0.5908 - val_loss: 1.4662 - val_accuracy: 0.4420\n",
            "Epoch 55/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0484 - accuracy: 0.5958 - val_loss: 1.3906 - val_accuracy: 0.4618\n",
            "Epoch 56/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0354 - accuracy: 0.5984 - val_loss: 1.3477 - val_accuracy: 0.4774\n",
            "Epoch 57/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0284 - accuracy: 0.6049 - val_loss: 1.4410 - val_accuracy: 0.4485\n",
            "Epoch 58/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0160 - accuracy: 0.6099 - val_loss: 1.3854 - val_accuracy: 0.4756\n",
            "Epoch 59/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 1.0008 - accuracy: 0.6173 - val_loss: 1.3981 - val_accuracy: 0.4583\n",
            "Epoch 60/200\n",
            "24590/24624 [============================>.] - ETA: 0s - loss: 1.0004 - accuracy: 0.6175Epoch 61/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.9729 - accuracy: 0.6278 - val_loss: 1.3779 - val_accuracy: 0.4764\n",
            "Epoch 62/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.9726 - accuracy: 0.6299 - val_loss: 1.3751 - val_accuracy: 0.4896\n",
            "Epoch 63/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.9548 - accuracy: 0.6377 - val_loss: 1.3724 - val_accuracy: 0.4945\n",
            "Epoch 64/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.9513 - accuracy: 0.6386 - val_loss: 1.3889 - val_accuracy: 0.4709\n",
            "Epoch 65/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.9414 - accuracy: 0.6427 - val_loss: 1.3370 - val_accuracy: 0.4870\n",
            "Epoch 66/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.9366 - accuracy: 0.6468 - val_loss: 1.3695 - val_accuracy: 0.4751\n",
            "Epoch 67/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.9272 - accuracy: 0.6516 - val_loss: 1.4175 - val_accuracy: 0.4747\n",
            "Epoch 68/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.9119 - accuracy: 0.6572 - val_loss: 1.3531 - val_accuracy: 0.4995\n",
            "Epoch 69/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.8940 - accuracy: 0.6648 - val_loss: 1.3539 - val_accuracy: 0.4847\n",
            "Epoch 70/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.8828 - accuracy: 0.6705 - val_loss: 1.3784 - val_accuracy: 0.4877\n",
            "Epoch 71/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.9029 - accuracy: 0.6612 - val_loss: 1.4354 - val_accuracy: 0.4667\n",
            "Epoch 72/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.8588 - accuracy: 0.6754 - val_loss: 1.3182 - val_accuracy: 0.5006\n",
            "Epoch 73/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.8516 - accuracy: 0.6832 - val_loss: 1.3145 - val_accuracy: 0.5023\n",
            "Epoch 74/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.8337 - accuracy: 0.6904 - val_loss: 1.4081 - val_accuracy: 0.4972\n",
            "Epoch 75/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.8246 - accuracy: 0.6926 - val_loss: 1.3544 - val_accuracy: 0.5010\n",
            "Epoch 76/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.8356 - accuracy: 0.6930 - val_loss: 1.3352 - val_accuracy: 0.5117\n",
            "Epoch 77/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.8448 - accuracy: 0.6907 - val_loss: 1.3749 - val_accuracy: 0.4981\n",
            "Epoch 78/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.8060 - accuracy: 0.6998 - val_loss: 1.5457 - val_accuracy: 0.4448\n",
            "Epoch 79/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.7684 - accuracy: 0.7114 - val_loss: 1.3238 - val_accuracy: 0.5258\n",
            "Epoch 80/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.7901 - accuracy: 0.7076 - val_loss: 1.3457 - val_accuracy: 0.5063\n",
            "Epoch 81/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.7506 - accuracy: 0.7232 - val_loss: 1.3612 - val_accuracy: 0.5063\n",
            "Epoch 82/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.7434 - accuracy: 0.7295 - val_loss: 1.4401 - val_accuracy: 0.4990\n",
            "Epoch 83/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.7251 - accuracy: 0.7357 - val_loss: 1.3587 - val_accuracy: 0.5107\n",
            "Epoch 84/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.7169 - accuracy: 0.7358 - val_loss: 1.3218 - val_accuracy: 0.5250\n",
            "Epoch 85/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.7131 - accuracy: 0.7406 - val_loss: 1.4167 - val_accuracy: 0.4940\n",
            "Epoch 86/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.7125 - accuracy: 0.7435 - val_loss: 1.3501 - val_accuracy: 0.5218\n",
            "Epoch 87/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6951 - accuracy: 0.7468 - val_loss: 1.3431 - val_accuracy: 0.5289\n",
            "Epoch 88/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6729 - accuracy: 0.7539 - val_loss: 1.3363 - val_accuracy: 0.5305\n",
            "Epoch 89/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6885 - accuracy: 0.7505 - val_loss: 1.3753 - val_accuracy: 0.5197\n",
            "Epoch 90/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6411 - accuracy: 0.7677 - val_loss: 1.4172 - val_accuracy: 0.5125\n",
            "Epoch 91/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.6462 - accuracy: 0.7666 - val_loss: 1.5036 - val_accuracy: 0.5026\n",
            "Epoch 92/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6306 - accuracy: 0.7731 - val_loss: 1.3688 - val_accuracy: 0.5456\n",
            "Epoch 93/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6229 - accuracy: 0.7780 - val_loss: 1.4262 - val_accuracy: 0.5195\n",
            "Epoch 94/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6181 - accuracy: 0.7792 - val_loss: 1.3829 - val_accuracy: 0.5372\n",
            "Epoch 95/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.5883 - accuracy: 0.7877 - val_loss: 1.3208 - val_accuracy: 0.5560\n",
            "Epoch 96/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.5817 - accuracy: 0.7897 - val_loss: 1.3949 - val_accuracy: 0.5372\n",
            "Epoch 97/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.5756 - accuracy: 0.7943 - val_loss: 1.4166 - val_accuracy: 0.5279\n",
            "Epoch 98/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.5693 - accuracy: 0.7998 - val_loss: 1.4498 - val_accuracy: 0.5286\n",
            "Epoch 99/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6872 - accuracy: 0.7615 - val_loss: 1.3221 - val_accuracy: 0.5374\n",
            "Epoch 100/200\n",
            "24624/24624 [==============================] - 34s 1ms/step - loss: 0.5455 - accuracy: 0.8062 - val_loss: 1.4054 - val_accuracy: 0.5417\n",
            "Epoch 101/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.5238 - accuracy: 0.8148 - val_loss: 1.3932 - val_accuracy: 0.5356\n",
            "Epoch 102/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.5156 - accuracy: 0.8180 - val_loss: 1.4666 - val_accuracy: 0.5380\n",
            "Epoch 103/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.5177 - accuracy: 0.8164 - val_loss: 1.3990 - val_accuracy: 0.5500\n",
            "Epoch 104/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.5256 - accuracy: 0.8126 - val_loss: 1.4563 - val_accuracy: 0.5404\n",
            "Epoch 105/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4986 - accuracy: 0.8241 - val_loss: 1.3734 - val_accuracy: 0.5520\n",
            "Epoch 106/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4865 - accuracy: 0.8289 - val_loss: 1.3073 - val_accuracy: 0.5694\n",
            "Epoch 107/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.5059 - accuracy: 0.8223 - val_loss: 1.3997 - val_accuracy: 0.5487\n",
            "Epoch 108/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4649 - accuracy: 0.8371 - val_loss: 1.4544 - val_accuracy: 0.5489\n",
            "Epoch 109/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4754 - accuracy: 0.8333 - val_loss: 1.3116 - val_accuracy: 0.5482\n",
            "Epoch 110/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4769 - accuracy: 0.8329 - val_loss: 1.4008 - val_accuracy: 0.5544\n",
            "Epoch 111/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4674 - accuracy: 0.8388 - val_loss: 1.3854 - val_accuracy: 0.5393\n",
            "Epoch 112/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4531 - accuracy: 0.8415 - val_loss: 1.3436 - val_accuracy: 0.5824\n",
            "Epoch 113/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4231 - accuracy: 0.8525 - val_loss: 1.4232 - val_accuracy: 0.5531\n",
            "Epoch 114/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4762 - accuracy: 0.8348 - val_loss: 1.5431 - val_accuracy: 0.5375\n",
            "Epoch 115/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4190 - accuracy: 0.8548 - val_loss: 1.5316 - val_accuracy: 0.5551\n",
            "Epoch 116/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4151 - accuracy: 0.8571 - val_loss: 1.5110 - val_accuracy: 0.5430\n",
            "Epoch 117/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4172 - accuracy: 0.8568 - val_loss: 1.4228 - val_accuracy: 0.5482\n",
            "Epoch 118/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4264 - accuracy: 0.8528 - val_loss: 1.4770 - val_accuracy: 0.5430\n",
            "Epoch 119/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3850 - accuracy: 0.8684 - val_loss: 1.3749 - val_accuracy: 0.5734\n",
            "Epoch 120/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4366 - accuracy: 0.8531 - val_loss: 1.4520 - val_accuracy: 0.5913\n",
            "Epoch 121/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3780 - accuracy: 0.8708 - val_loss: 1.3562 - val_accuracy: 0.5798\n",
            "Epoch 122/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3765 - accuracy: 0.8694 - val_loss: 1.4890 - val_accuracy: 0.5666\n",
            "Epoch 123/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3793 - accuracy: 0.8698 - val_loss: 1.5604 - val_accuracy: 0.5776\n",
            "Epoch 124/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4048 - accuracy: 0.8644 - val_loss: 1.3845 - val_accuracy: 0.5793\n",
            "Epoch 125/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4147 - accuracy: 0.8585 - val_loss: 1.4470 - val_accuracy: 0.5812\n",
            "Epoch 126/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3167 - accuracy: 0.8923 - val_loss: 1.3663 - val_accuracy: 0.5975\n",
            "Epoch 127/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.4300 - accuracy: 0.8548 - val_loss: 1.4640 - val_accuracy: 0.5708\n",
            "Epoch 128/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3184 - accuracy: 0.8897 - val_loss: 1.5562 - val_accuracy: 0.5731\n",
            "Epoch 129/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3843 - accuracy: 0.8689 - val_loss: 1.5021 - val_accuracy: 0.5645\n",
            "Epoch 130/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3067 - accuracy: 0.8957 - val_loss: 1.5609 - val_accuracy: 0.5804\n",
            "Epoch 131/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.4577 - accuracy: 0.8588 - val_loss: 1.4601 - val_accuracy: 0.5785\n",
            "Epoch 132/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2997 - accuracy: 0.8977 - val_loss: 1.6299 - val_accuracy: 0.5437\n",
            "Epoch 133/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3339 - accuracy: 0.8880 - val_loss: 1.3748 - val_accuracy: 0.6135\n",
            "Epoch 134/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3209 - accuracy: 0.8900 - val_loss: 1.4579 - val_accuracy: 0.5885\n",
            "Epoch 135/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2955 - accuracy: 0.8992 - val_loss: 1.5731 - val_accuracy: 0.5268\n",
            "Epoch 136/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3186 - accuracy: 0.8936 - val_loss: 1.6066 - val_accuracy: 0.6051\n",
            "Epoch 137/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3006 - accuracy: 0.8981 - val_loss: 1.4377 - val_accuracy: 0.6020\n",
            "Epoch 138/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2823 - accuracy: 0.9049 - val_loss: 1.5567 - val_accuracy: 0.5918\n",
            "Epoch 139/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2895 - accuracy: 0.9022 - val_loss: 1.5291 - val_accuracy: 0.6035\n",
            "Epoch 140/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3397 - accuracy: 0.8860 - val_loss: 1.5659 - val_accuracy: 0.6142\n",
            "Epoch 141/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2792 - accuracy: 0.9071 - val_loss: 1.4101 - val_accuracy: 0.6053\n",
            "Epoch 142/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2980 - accuracy: 0.9036 - val_loss: 1.3722 - val_accuracy: 0.6041\n",
            "Epoch 143/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3057 - accuracy: 0.8982 - val_loss: 1.5116 - val_accuracy: 0.6023\n",
            "Epoch 144/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2471 - accuracy: 0.9170 - val_loss: 1.4442 - val_accuracy: 0.6090\n",
            "Epoch 145/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2941 - accuracy: 0.9022 - val_loss: 1.4492 - val_accuracy: 0.5804\n",
            "Epoch 146/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2545 - accuracy: 0.9163 - val_loss: 1.4849 - val_accuracy: 0.5960\n",
            "Epoch 147/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2780 - accuracy: 0.9092 - val_loss: 1.4991 - val_accuracy: 0.5825\n",
            "Epoch 148/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2535 - accuracy: 0.9135 - val_loss: 1.4904 - val_accuracy: 0.6010\n",
            "Epoch 149/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.2909 - accuracy: 0.9057 - val_loss: 1.3936 - val_accuracy: 0.5378\n",
            "Epoch 150/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2785 - accuracy: 0.9076 - val_loss: 1.5147 - val_accuracy: 0.6023\n",
            "Epoch 151/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2488 - accuracy: 0.9200 - val_loss: 1.3268 - val_accuracy: 0.5947\n",
            "Epoch 152/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.2529 - accuracy: 0.9183 - val_loss: 1.5057 - val_accuracy: 0.5997\n",
            "Epoch 153/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.2517 - accuracy: 0.9171 - val_loss: 1.5996 - val_accuracy: 0.5989\n",
            "Epoch 154/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.2593 - accuracy: 0.9160 - val_loss: 2.1287 - val_accuracy: 0.5013\n",
            "Epoch 155/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.3049 - accuracy: 0.9003 - val_loss: 1.4565 - val_accuracy: 0.5789\n",
            "Epoch 156/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.2178 - accuracy: 0.9294 - val_loss: 1.4213 - val_accuracy: 0.6066\n",
            "Epoch 157/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.2304 - accuracy: 0.9248 - val_loss: 1.4717 - val_accuracy: 0.6079\n",
            "Epoch 158/200\n",
            "24624/24624 [==============================] - 36s 1ms/step - loss: 0.2357 - accuracy: 0.9211 - val_loss: 1.7164 - val_accuracy: 0.5536\n",
            "Epoch 159/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2264 - accuracy: 0.9252 - val_loss: 1.6337 - val_accuracy: 0.5952\n",
            "Epoch 160/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2568 - accuracy: 0.9186 - val_loss: 1.4147 - val_accuracy: 0.6014\n",
            "Epoch 161/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2519 - accuracy: 0.9217 - val_loss: 1.5377 - val_accuracy: 0.6049\n",
            "Epoch 162/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2671 - accuracy: 0.9167 - val_loss: 1.4821 - val_accuracy: 0.6186\n",
            "Epoch 163/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2085 - accuracy: 0.9325 - val_loss: 1.4402 - val_accuracy: 0.6199\n",
            "Epoch 164/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2094 - accuracy: 0.9319 - val_loss: 1.6955 - val_accuracy: 0.6103\n",
            "Epoch 165/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3223 - accuracy: 0.8940 - val_loss: 1.5109 - val_accuracy: 0.6012\n",
            "Epoch 166/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1704 - accuracy: 0.9432 - val_loss: 1.5893 - val_accuracy: 0.6264\n",
            "Epoch 167/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1739 - accuracy: 0.9428 - val_loss: 1.5292 - val_accuracy: 0.6145\n",
            "Epoch 168/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2669 - accuracy: 0.9162 - val_loss: 1.6774 - val_accuracy: 0.6231\n",
            "Epoch 169/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1903 - accuracy: 0.9388 - val_loss: 1.4532 - val_accuracy: 0.6051\n",
            "Epoch 170/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2462 - accuracy: 0.9270 - val_loss: 1.4540 - val_accuracy: 0.6131\n",
            "Epoch 171/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1965 - accuracy: 0.9341 - val_loss: 1.4951 - val_accuracy: 0.6311\n",
            "Epoch 172/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3547 - accuracy: 0.8908 - val_loss: 1.3683 - val_accuracy: 0.6360\n",
            "Epoch 173/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1572 - accuracy: 0.9478 - val_loss: 1.7133 - val_accuracy: 0.5937\n",
            "Epoch 174/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1756 - accuracy: 0.9408 - val_loss: 1.4936 - val_accuracy: 0.6233\n",
            "Epoch 175/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1819 - accuracy: 0.9400 - val_loss: 1.4797 - val_accuracy: 0.6360\n",
            "Epoch 176/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.3073 - accuracy: 0.9014 - val_loss: 1.4091 - val_accuracy: 0.6074\n",
            "Epoch 177/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1704 - accuracy: 0.9438 - val_loss: 1.8172 - val_accuracy: 0.5859\n",
            "Epoch 178/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1668 - accuracy: 0.9452 - val_loss: 1.4688 - val_accuracy: 0.6259\n",
            "Epoch 179/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1843 - accuracy: 0.9399 - val_loss: 1.5348 - val_accuracy: 0.6241\n",
            "Epoch 180/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2312 - accuracy: 0.9245 - val_loss: 1.3218 - val_accuracy: 0.6200\n",
            "Epoch 181/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1828 - accuracy: 0.9397 - val_loss: 1.6784 - val_accuracy: 0.5283\n",
            "Epoch 182/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2344 - accuracy: 0.9275 - val_loss: 1.4924 - val_accuracy: 0.6360\n",
            "Epoch 183/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2627 - accuracy: 0.9213 - val_loss: 1.5357 - val_accuracy: 0.6183\n",
            "Epoch 184/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2107 - accuracy: 0.9359 - val_loss: 1.3813 - val_accuracy: 0.6246\n",
            "Epoch 185/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1849 - accuracy: 0.9402 - val_loss: 1.5438 - val_accuracy: 0.6067\n",
            "Epoch 186/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1643 - accuracy: 0.9470 - val_loss: 1.4977 - val_accuracy: 0.6176\n",
            "Epoch 187/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1944 - accuracy: 0.9388 - val_loss: 1.3349 - val_accuracy: 0.6467\n",
            "Epoch 188/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1635 - accuracy: 0.9467 - val_loss: 1.3713 - val_accuracy: 0.6317\n",
            "Epoch 189/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2067 - accuracy: 0.9326 - val_loss: 1.4539 - val_accuracy: 0.6205\n",
            "Epoch 190/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1921 - accuracy: 0.9388 - val_loss: 1.4661 - val_accuracy: 0.6225\n",
            "Epoch 191/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1770 - accuracy: 0.9438 - val_loss: 1.4941 - val_accuracy: 0.6308\n",
            "Epoch 192/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1946 - accuracy: 0.9413 - val_loss: 1.4437 - val_accuracy: 0.6220\n",
            "Epoch 193/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1667 - accuracy: 0.9454 - val_loss: 1.5019 - val_accuracy: 0.6106\n",
            "Epoch 194/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1678 - accuracy: 0.9467 - val_loss: 1.5316 - val_accuracy: 0.6235\n",
            "Epoch 195/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1695 - accuracy: 0.9468 - val_loss: 1.6196 - val_accuracy: 0.6340\n",
            "Epoch 196/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1941 - accuracy: 0.9360 - val_loss: 1.5115 - val_accuracy: 0.6335\n",
            "Epoch 197/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.2684 - accuracy: 0.9193 - val_loss: 1.3422 - val_accuracy: 0.5359\n",
            "Epoch 198/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.6589 - accuracy: 0.8341 - val_loss: 1.2994 - val_accuracy: 0.6074\n",
            "Epoch 199/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1941 - accuracy: 0.9352 - val_loss: 1.4589 - val_accuracy: 0.6376\n",
            "Epoch 200/200\n",
            "24624/24624 [==============================] - 35s 1ms/step - loss: 0.1561 - accuracy: 0.9510 - val_loss: 1.3848 - val_accuracy: 0.5869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J34M7NykYPJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "3213f58b-cf62-43f8-c27d-5a12d301f718"
      },
      "source": [
        "plt.plot(model_history.history['accuracy'])\n",
        "plt.plot(model_history.history['val_accuracy'])\n",
        "plt.title('Training Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAFsohbvkYPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "dfe0568e-046c-4060-a6a3-2ba3af1c39f0"
      },
      "source": [
        "# Save model and weights\n",
        "model_name = 'male_cnn1d_aug_exp.h5'\n",
        "model_path='/gdrive/My Drive/Audio_files/saved_models/'\n",
        "\n",
        "\n",
        "model.save(model_path+model_name)\n",
        "print('Save model and weights at %s ' % model_path)\n",
        "\n",
        "# Save the model to disk\n",
        "model_json = model.to_json()\n",
        "with open((model_path+\"male_cnn1d_aug_exp.json\"), \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Save model and weights at /gdrive/My Drive/Audio_files/saved_models/ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARwERpf6kYPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "90670be8-52d9-45b2-e2a4-3415e1cc0ec1"
      },
      "source": [
        "# loading json and model architecture \n",
        "model_path='/gdrive/My Drive/Audio_files/saved_models/'\n",
        "json_file = open((model_path+'male_cnn1d_aug_exp.json'), 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights((model_path+\"male_cnn1d_aug_exp.h5\"))\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# Keras optimiser\n",
        "opt = keras.optimizers.rmsprop(lr=0.00001, decay=1e-6)\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n",
            "accuracy: 58.69%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwZfE-FlkYPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "508abc83-2bd8-4749-8d7d-90f077b5be9f"
      },
      "source": [
        "preds = loaded_model.predict(X_test, \n",
        "                         batch_size=16, \n",
        "                         verbose=1)\n",
        "\n",
        "preds=preds.argmax(axis=1)\n",
        "preds"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6156/6156 [==============================] - 2s 326us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 4, 5, ..., 4, 6, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdv1yevNkYPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "a255fdf7-40f0-4f6e-e7d6-8803453eac10"
      },
      "source": [
        "# predictions \n",
        "preds = preds.astype(int).flatten()\n",
        "preds = (lb.inverse_transform((preds)))\n",
        "preds = pd.DataFrame({'predictedvalues': preds})\n",
        "\n",
        "# Actual labels\n",
        "actual=y_test.argmax(axis=1)\n",
        "actual = actual.astype(int).flatten()\n",
        "actual = (lb.inverse_transform((actual)))\n",
        "actual = pd.DataFrame({'actualvalues': actual})\n",
        "\n",
        "# combined both of them into a single dataframe\n",
        "finaldf = actual.join(preds)\n",
        "finaldf[170:180]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actualvalues</th>\n",
              "      <th>predictedvalues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>male_sad</td>\n",
              "      <td>male_sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>male_happy</td>\n",
              "      <td>male_happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>male_happy</td>\n",
              "      <td>male_happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>male_fear</td>\n",
              "      <td>male_happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>male_fear</td>\n",
              "      <td>male_fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>male_fear</td>\n",
              "      <td>male_happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>male_happy</td>\n",
              "      <td>male_happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>male_angry</td>\n",
              "      <td>male_angry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>male_angry</td>\n",
              "      <td>male_disgust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>male_sad</td>\n",
              "      <td>male_sad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    actualvalues predictedvalues\n",
              "170     male_sad        male_sad\n",
              "171   male_happy      male_happy\n",
              "172   male_happy      male_happy\n",
              "173    male_fear      male_happy\n",
              "174    male_fear       male_fear\n",
              "175    male_fear      male_happy\n",
              "176   male_happy      male_happy\n",
              "177   male_angry      male_angry\n",
              "178   male_angry    male_disgust\n",
              "179     male_sad        male_sad"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jcrthjMkYPh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "c32e3e29-0ca2-4ef9-feb0-970b83bb4584"
      },
      "source": [
        "# Write out the predictions to disk\n",
        "finaldf.to_csv('Predictions.csv', index=False)\n",
        "finaldf.groupby('predictedvalues').count()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actualvalues</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predictedvalues</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>male_angry</th>\n",
              "      <td>743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male_disgust</th>\n",
              "      <td>1085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male_fear</th>\n",
              "      <td>864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male_happy</th>\n",
              "      <td>1269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male_neutral</th>\n",
              "      <td>1019</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male_sad</th>\n",
              "      <td>1025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male_surprise</th>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 actualvalues\n",
              "predictedvalues              \n",
              "male_angry                743\n",
              "male_disgust             1085\n",
              "male_fear                 864\n",
              "male_happy               1269\n",
              "male_neutral             1019\n",
              "male_sad                 1025\n",
              "male_surprise             151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmM44ZlcvKrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the confusion matrix heat map plot\n",
        "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "\n",
        "    df_cm = pd.DataFrame(\n",
        "        confusion_matrix, index=class_names, columns=class_names, \n",
        "    )\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "        \n",
        "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "# Gender recode function\n",
        "def gender(row):\n",
        "    if row == 'male_angry' or 'male_fear' or 'male_happy' or 'male_sad' or 'male_surprise' or 'male_neutral' or 'male_disgust':\n",
        "        return 'male'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Takv8VWLvGLu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "outputId": "9eb28703-e766-41a2-bbba-84d50b14a12d"
      },
      "source": [
        "# Get the predictions file \n",
        "finaldf = pd.read_csv(\"Predictions.csv\")\n",
        "classes = finaldf.actualvalues.unique()\n",
        "classes.sort()    \n",
        "\n",
        "# Confusion matrix \n",
        "c = confusion_matrix(finaldf.actualvalues, finaldf.predictedvalues)\n",
        "print(accuracy_score(finaldf.actualvalues, finaldf.predictedvalues))\n",
        "print_confusion_matrix(c, class_names = classes)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6647173489278753\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n9U1a2zvH7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "5e9ee2ad-19a0-45a7-a2b6-d9d7aa8b0dbb"
      },
      "source": [
        "# Classification report \n",
        "classes = finaldf.actualvalues.unique()\n",
        "classes.sort()    \n",
        "print(classification_report(finaldf.actualvalues, finaldf.predictedvalues, target_names=classes))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "   male_angry       0.89      0.62      0.73      1075\n",
            " male_disgust       0.61      0.68      0.64       960\n",
            "    male_fear       0.65      0.57      0.61       982\n",
            "   male_happy       0.55      0.70      0.62       992\n",
            " male_neutral       0.67      0.70      0.68       984\n",
            "     male_sad       0.67      0.72      0.69       964\n",
            "male_surprise       0.92      0.70      0.79       199\n",
            "\n",
            "     accuracy                           0.66      6156\n",
            "    macro avg       0.71      0.67      0.68      6156\n",
            " weighted avg       0.68      0.66      0.67      6156\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7HhBwW-w_qJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate\n",
        "from keras import optimizers\n",
        "import numpy as np\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Sequential\n",
        "np.random.seed(4)\n",
        "from keras.layers import LeakyReLU\n",
        "\n",
        "\n",
        "adam = optimizers.Adam(lr=0.0005)\n",
        "\n",
        "\n",
        "from keras.layers import LeakyReLU\n",
        "# now add a ReLU layer explicitly:\n",
        "\n",
        "model_3 = Sequential()\n",
        "model_3.add(LSTM(32, return_sequences=True,activation='relu', input_shape=(X_train.shape[1],1)))\n",
        "#model_3.add(LeakyReLU(alpha=0.0001))\n",
        "#model_3.add(LSTM(5 ,return_sequences=True, activation='relu'))\n",
        "#model_3.add(LeakyReLU(alpha=0.0001))\n",
        "model_3.add(LSTM(32, activation='relu'))\n",
        "#model_3.add(LeakyReLU(alpha=0.0001))\n",
        "model_3.add(Dense(7,activation = 'softmax'))  # return a single vector of dimension 32\n",
        "model_3.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['acc'])\n",
        "#plot_model(model_3, to_file='model_3.png')\n",
        "\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edGDefkhN4E1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "388ebc7f-b408-4d19-f86e-a73e8916914c"
      },
      "source": [
        "history_3=model_3.fit(x=X_train, y=y_train, batch_size=50, epochs=100 , shuffle=True, validation_data=(X_test, y_test),verbose=1)\n",
        "evaluation_3 = model_3.evaluate(X_test, y_test)\n",
        "# serialize model to JSON\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 24624 samples, validate on 6156 samples\n",
            "Epoch 1/100\n",
            "16650/24624 [===================>..........] - ETA: 1:45 - loss: 5832591.7255 - acc: 0.1664"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-68d58a533d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevaluation_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# serialize model to JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}